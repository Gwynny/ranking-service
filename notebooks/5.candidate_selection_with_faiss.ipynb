{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gwyn\\Documents\\GitHub\\ranking_service\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import json\n",
    "import mlflow\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from src.data.text_retriever import TextRetriever\n",
    "from src.models.knrm_model import KNRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_DIR = os.path.abspath(os.path.join('', os.pardir))\n",
    "DOCUMENTS_PATH = PARENT_DIR + '/data/processed/documents.json'\n",
    "ML_RUNS_PATH = PARENT_DIR + '/models/ml_runs/'\n",
    "\n",
    "with open(DOCUMENTS_PATH) as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "if mlflow.get_tracking_uri() != 'file:///' + ML_RUNS_PATH:\n",
    "    mlflow.set_tracking_uri('file:///' + ML_RUNS_PATH)\n",
    "EXP_ID = mlflow.get_experiment_by_name('QuoraRankingExtendedTraining').experiment_id\n",
    "RUN_ID = mlflow.search_runs(experiment_ids=[EXP_ID])['run_id'][0]\n",
    "\n",
    "MODEL_URI = \"runs:/{}/model\".format(RUN_ID)\n",
    "VOCAB_URI = \"runs:/{}/vocab\".format(RUN_ID)\n",
    "knrm = mlflow.pytorch.load_model(MODEL_URI)\n",
    "vocab = mlflow.artifacts.load_dict(VOCAB_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537916"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs, docs = [], []\n",
    "for idx in documents:\n",
    "    idxs.append(int(idx))\n",
    "    docs.append(documents[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "oov_val = vocab['OOV']\n",
    "tr = TextRetriever()\n",
    "emb_layer = knrm.embeddings.state_dict()['weight']\n",
    "for d in docs:\n",
    "    tmp_emb = [vocab.get(w, oov_val) for w in tr.lower_and_tokenize_words(d)]\n",
    "    tmp_emb = emb_layer[tmp_emb].mean(dim=0)\n",
    "    embeddings.append(np.array(tmp_emb))\n",
    "\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index = faiss.IndexIDMap(index)\n",
    "index.add_with_ids(embeddings, np.array(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111886618\n"
     ]
    }
   ],
   "source": [
    "def get_memory(index):\n",
    "    faiss.write_index(index, './temp.index')\n",
    "    file_size = os.path.getsize('./temp.index')\n",
    "    os.remove('./temp.index')\n",
    "    return file_size\n",
    "\n",
    "print(get_memory(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How is the life of a math student?'\n",
    "\n",
    "q_vector = [vocab.get(token, oov_val) for token in tr.lower_and_tokenize_words(query)]\n",
    "q_emb = emb_layer[q_vector].mean(dim=0).reshape(1, -1)\n",
    "q_emb = np.array(q_emb).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, I = index.search(q_emb, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text_list, vocab):\n",
    "    tokenized = []\n",
    "    for text in text_list:\n",
    "        tokenized_text = tr.lower_and_tokenize_words(text)\n",
    "        token_idxs = [vocab.get(i, vocab[\"OOV\"]) for i in tokenized_text]\n",
    "        tokenized.append(token_idxs)\n",
    "    max_len = 30\n",
    "    tokenized = [elem + [0] * (max_len - len(elem)) for elem in tokenized]\n",
    "    tokenized = torch.LongTensor(tokenized)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = [(str(i), documents[str(i)]) for i in I[0] if i != -1]\n",
    "inputs = dict()\n",
    "inputs['query'] = text_to_token_ids([query] * len(cands), vocab)\n",
    "inputs['document'] = text_to_token_ids([cnd[1] for cnd in cands], vocab)\n",
    "scores = knrm.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ids = scores.reshape(-1).argsort(descending=True)\n",
    "res_ids = res_ids[:10]\n",
    "res = [cands[i] for i in res_ids.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How is the life of a math student?',\n",
       " [('537770',\n",
       "   'How hard is it to get into Art Center College of Design, CA for a middle-class Indian student with science background?'),\n",
       "  ('337183',\n",
       "   \"What does a librarian with a library science master's degree do? What is it like a day in the life of a librarian?\"),\n",
       "  ('213221',\n",
       "   'How is the life of a math student? Could you describe your own experiences?'),\n",
       "  ('38754',\n",
       "   \"What is more important in a letter of recommendation, the teacher's designation or whatever the teacher writes about the student?\"),\n",
       "  ('144409',\n",
       "   'Since each of us has been a student first, what is the harshest thing a teacher taught you?'),\n",
       "  ('20643',\n",
       "   'What is the best time table for a student of maths and science of class 11th?'),\n",
       "  ('29651',\n",
       "   'What is the importance of clubs(technical) in a life of a engineering student?'),\n",
       "  ('203537', 'How is the life/experience of a student at MBBS college?'),\n",
       "  ('250533',\n",
       "   'What is the best field of engineering to a student proficient in every thing except physics?'),\n",
       "  ('459548',\n",
       "   'What is the best way to read through/study a college level math book?')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.0195254 , 0.08607575, 0.04110535]),\n",
       " array([ 0.02807871, -0.02455939,  0.19534954]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix[0][:3], emb_matrix[1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02380205, 0.03075818, 0.11822744])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix[[0, 1], :3].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_val = self.vocab[\"OOV\"]\n",
    "\n",
    "embeddings = []\n",
    "emb_layer = self.model.embeddings.state_dict()['weight']\n",
    "for d in docs:\n",
    "    tmp_emb = [self.vocab.get(w, oov_val) for w in self._simple_preproc(d)]\n",
    "    tmp_emb = emb_layer[tmp_emb].mean(dim = 0)\n",
    "    embeddings.append(np.array(tmp_emb))          \n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(np.float32)\n",
    "self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "self.index = faiss.IndexIDMap(self.index)\n",
    "self.index.add_with_ids(embeddings, np.array(idxs))\n",
    "index_size = self.index.ntotal\n",
    "global index_is_ready\n",
    "index_is_ready = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d = 64                          # dimension\n",
    "nb = 100000                     # database size\n",
    "nq = 100                       # nb of queries\n",
    "np.random.seed(1234)             # make reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "import faiss                   # make faiss available\n",
    "index = faiss.IndexFlatL2(d)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(xb)                  # add vectors to the index\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 393 363  78]\n",
      " [  1 555 277 364]\n",
      " [  2 304 101  13]\n",
      " [  3 173  18 182]\n",
      " [  4 288 370 531]]\n",
      "[[0.        7.175174  7.2076287 7.251163 ]\n",
      " [0.        6.323565  6.684582  6.799944 ]\n",
      " [0.        5.7964087 6.3917365 7.2815127]\n",
      " [0.        7.277905  7.5279875 7.6628447]\n",
      " [0.        6.763804  7.295122  7.368814 ]]\n",
      "[[ 381  207  210  477]\n",
      " [ 526  911  142   72]\n",
      " [ 838  527 1290  425]\n",
      " [ 196  184  164  359]\n",
      " [ 526  377  120  425]]\n",
      "[[ 801  781  933  385]\n",
      " [1073  786 1076  381]\n",
      " [ 549  244  100 1008]\n",
      " [ 917  140  965   68]\n",
      " [ 511  789  225  781]]\n"
     ]
    }
   ],
   "source": [
    "k = 4                          # we want to see 4 nearest neighbors\n",
    "D, I = index.search(xb[:5], k) # sanity check\n",
    "print(I)\n",
    "print(D)\n",
    "D, I = index.search(xq, k)     # actual search\n",
    "print(I[:5])                   # neighbors of the 5 first queries\n",
    "print(I[-5:])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.012596  , 0.6246662 , 0.56637293, 0.95298845, 0.08366151],\n",
       "       dtype=float32),\n",
       " array([0.11797123, 0.5159861 , 0.40499622, 0.9996496 , 0.10857001],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq[0], xb[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05175545, 0.13396178, 0.14332213, 0.15562324],\n",
       "       [0.05284711, 0.05362   , 0.06072539, 0.07184806],\n",
       "       [0.0321276 , 0.04367728, 0.08774583, 0.0887173 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "73fe5d56cd748ae96ed2ac39fb9a89f921657ed8d6f28eadcafdf9d84d668e00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
